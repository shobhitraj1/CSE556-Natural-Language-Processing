{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:13.714753Z",
     "iopub.status.busy": "2025-03-16T09:41:13.714557Z",
     "iopub.status.idle": "2025-03-16T09:41:18.176491Z",
     "shell.execute_reply": "2025-03-16T09:41:18.175466Z",
     "shell.execute_reply.started": "2025-03-16T09:41:13.714734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-crf\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:18.177952Z",
     "iopub.status.busy": "2025-03-16T09:41:18.177608Z",
     "iopub.status.idle": "2025-03-16T09:41:39.310996Z",
     "shell.execute_reply": "2025-03-16T09:41:39.310302Z",
     "shell.execute_reply.started": "2025-03-16T09:41:18.177915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
    "import matplotlib.pyplot as plt\n",
    "from torchcrf import CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:39.312451Z",
     "iopub.status.busy": "2025-03-16T09:41:39.311778Z",
     "iopub.status.idle": "2025-03-16T09:41:43.638406Z",
     "shell.execute_reply": "2025-03-16T09:41:43.637571Z",
     "shell.execute_reply.started": "2025-03-16T09:41:39.312420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad_v2\")\n",
    "train_subset = squad[\"train\"].select(range(15000))\n",
    "val_subset = squad[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:43.639361Z",
     "iopub.status.busy": "2025-03-16T09:41:43.639161Z",
     "iopub.status.idle": "2025-03-16T09:41:47.513996Z",
     "shell.execute_reply": "2025-03-16T09:41:47.513346Z",
     "shell.execute_reply.started": "2025-03-16T09:41:43.639343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"SpanBERT/spanbert-base-cased\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:47.515222Z",
     "iopub.status.busy": "2025-03-16T09:41:47.514920Z",
     "iopub.status.idle": "2025-03-16T09:41:47.522000Z",
     "shell.execute_reply": "2025-03-16T09:41:47.521282Z",
     "shell.execute_reply.started": "2025-03-16T09:41:47.515195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def binary_search(arr, target):\n",
    "    lo, hi = 0, len(arr)\n",
    "    while lo < hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        if target < arr[mid]:\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid + 1\n",
    "    return lo\n",
    "\n",
    "def prepare_features(dataset):\n",
    "    tokenized_dataset = tokenizer(\n",
    "        dataset[\"question\"],\n",
    "        dataset[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    overflow_to_sample_mapping = tokenized_dataset.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_mapping = tokenized_dataset.pop(\"offset_mapping\")\n",
    "    \n",
    "    tokenized_dataset[\"start_positions\"] = []\n",
    "    tokenized_dataset[\"end_positions\"] = []\n",
    "\n",
    "    idx = -1\n",
    "\n",
    "    for offset in offset_mapping:\n",
    "        idx += 1\n",
    "        sample_idx = overflow_to_sample_mapping[idx]\n",
    "\n",
    "        answer = dataset[\"answers\"][sample_idx]\n",
    "\n",
    "        if len(answer[\"text\"]) == 0:\n",
    "            # No answer found\n",
    "            tokenized_dataset[\"start_positions\"].append(0)\n",
    "            tokenized_dataset[\"end_positions\"].append(0)\n",
    "            continue\n",
    "\n",
    "        start_char_idx = answer[\"answer_start\"][0]\n",
    "        end_char_idx = start_char_idx + len(answer[\"text\"][0])\n",
    "\n",
    "        start_offsets = [token[0] for token in offset]\n",
    "        end_offsets = [token[1] for token in offset]\n",
    "\n",
    "        token_start_index = binary_search(start_offsets, start_char_idx) - 1\n",
    "        token_start_index = max(0, token_start_index)\n",
    "\n",
    "        token_end_index = binary_search(end_offsets, end_char_idx) - 1\n",
    "        token_end_index = max(token_start_index, token_end_index)\n",
    "\n",
    "        if offset[token_start_index][0] > start_char_idx or offset[token_end_index][1] < end_char_idx:\n",
    "            tokenized_dataset[\"start_positions\"].append(0)\n",
    "            tokenized_dataset[\"end_positions\"].append(0)\n",
    "        else:\n",
    "            tokenized_dataset[\"start_positions\"].append(token_start_index)\n",
    "            tokenized_dataset[\"end_positions\"].append(token_end_index)\n",
    "    \n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:41:47.524301Z",
     "iopub.status.busy": "2025-03-16T09:41:47.524103Z",
     "iopub.status.idle": "2025-03-16T09:42:00.952085Z",
     "shell.execute_reply": "2025-03-16T09:42:00.951452Z",
     "shell.execute_reply.started": "2025-03-16T09:41:47.524283Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89875801018549dbaecc6a167dd59925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_subset.map(prepare_features, batched=True, remove_columns=train_subset.column_names)\n",
    "val_dataset = val_subset.map(prepare_features, batched=True, remove_columns=val_subset.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpanBERT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:42:00.953395Z",
     "iopub.status.busy": "2025-03-16T09:42:00.953161Z",
     "iopub.status.idle": "2025-03-16T09:42:03.156403Z",
     "shell.execute_reply": "2025-03-16T09:42:03.155287Z",
     "shell.execute_reply.started": "2025-03-16T09:42:00.953355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manan/anaconda3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_spanbert = AutoModelForQuestionAnswering.from_pretrained(\"SpanBERT/spanbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:42:03.158331Z",
     "iopub.status.busy": "2025-03-16T09:42:03.158051Z",
     "iopub.status.idle": "2025-03-16T09:42:03.307192Z",
     "shell.execute_reply": "2025-03-16T09:42:03.306457Z",
     "shell.execute_reply.started": "2025-03-16T09:42:03.158304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/SpanBERT\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    # fp16=True,  # enable mixed precision training for speed\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"exact_match\",\n",
    "    greater_is_better=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:42:03.308392Z",
     "iopub.status.busy": "2025-03-16T09:42:03.308075Z",
     "iopub.status.idle": "2025-03-16T09:42:03.312832Z",
     "shell.execute_reply": "2025-03-16T09:42:03.311971Z",
     "shell.execute_reply.started": "2025-03-16T09:42:03.308347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def exact_match_score(predictions, references):\n",
    "    assert len(predictions) == len(references), \"Lists must have the same length\"\n",
    "    matches = sum(p == r for p, r in zip(predictions, references))\n",
    "    return matches / len(references) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:42:03.314073Z",
     "iopub.status.busy": "2025-03-16T09:42:03.313742Z",
     "iopub.status.idle": "2025-03-16T09:42:03.325692Z",
     "shell.execute_reply": "2025-03-16T09:42:03.324916Z",
     "shell.execute_reply.started": "2025-03-16T09:42:03.314042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    start_predictions, end_predictions = predictions\n",
    "    start_label_ids, end_label_ids = labels\n",
    "    \n",
    "    start_pred = np.argmax(start_predictions, axis=1)\n",
    "    end_pred = np.argmax(end_predictions, axis=1)\n",
    "    \n",
    "    pred_answers = []\n",
    "    ref_answers = []\n",
    "    for i in range(len(start_pred)):\n",
    "        pred_answers.append((start_pred[i], end_pred[i]))\n",
    "        ref_answers.append((start_label_ids[i], end_label_ids[i]))\n",
    "\n",
    "    score_all = exact_match_score(pred_answers, ref_answers)\n",
    "\n",
    "    non_empty_indices = []\n",
    "    for i, (s, e) in enumerate(zip(start_label_ids, end_label_ids)):\n",
    "        if not (s == 0 and e == 0):\n",
    "            non_empty_indices.append(i)\n",
    "\n",
    "    if len(non_empty_indices) == 0:\n",
    "        return {\"exact_match_non_empty\": 0.0, \"exact_match\": score_all}\n",
    "\n",
    "    filtered_start_preds = np.argmax(start_predictions[non_empty_indices], axis=1)\n",
    "    filtered_end_preds = np.argmax(end_predictions[non_empty_indices], axis=1)\n",
    "    filtered_start_labels = start_label_ids[non_empty_indices]\n",
    "    filtered_end_labels = end_label_ids[non_empty_indices]\n",
    "\n",
    "    pred_answers = list(zip(filtered_start_preds, filtered_end_preds))\n",
    "    ref_answers = list(zip(filtered_start_labels, filtered_end_labels))\n",
    "    \n",
    "    score = exact_match_score(pred_answers, ref_answers)\n",
    "    return {\"exact_match_non_empty\": score, \"exact_match\": score_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:42:03.326795Z",
     "iopub.status.busy": "2025-03-16T09:42:03.326516Z",
     "iopub.status.idle": "2025-03-16T09:42:05.507154Z",
     "shell.execute_reply": "2025-03-16T09:42:05.506535Z",
     "shell.execute_reply.started": "2025-03-16T09:42:03.326766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer_spanbert = Trainer(\n",
    "    model=model_spanbert,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:43:37.498163Z",
     "iopub.status.busy": "2025-03-16T09:43:37.497856Z",
     "iopub.status.idle": "2025-03-16T11:07:35.862130Z",
     "shell.execute_reply": "2025-03-16T11:07:35.861475Z",
     "shell.execute_reply.started": "2025-03-16T09:43:37.498130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2868/2868 1:23:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match Non Empty</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.345900</td>\n",
       "      <td>2.181549</td>\n",
       "      <td>46.296061</td>\n",
       "      <td>26.491299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.631400</td>\n",
       "      <td>2.122664</td>\n",
       "      <td>50.507352</td>\n",
       "      <td>34.842251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.308900</td>\n",
       "      <td>2.045232</td>\n",
       "      <td>50.235070</td>\n",
       "      <td>37.663848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.116700</td>\n",
       "      <td>2.207699</td>\n",
       "      <td>51.614631</td>\n",
       "      <td>41.022117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.963500</td>\n",
       "      <td>2.264676</td>\n",
       "      <td>49.999092</td>\n",
       "      <td>40.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.860800</td>\n",
       "      <td>2.447841</td>\n",
       "      <td>50.398439</td>\n",
       "      <td>41.542527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2868, training_loss=1.5048309376715283, metrics={'train_runtime': 5038.01, 'train_samples_per_second': 18.208, 'train_steps_per_second': 0.569, 'total_flos': 1.7977347511815168e+16, 'train_loss': 1.5048309376715283, 'epoch': 6.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_spanbert.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:07:48.695528Z",
     "iopub.status.busy": "2025-03-16T11:07:48.695206Z",
     "iopub.status.idle": "2025-03-16T11:11:04.103909Z",
     "shell.execute_reply": "2025-03-16T11:11:04.103183Z",
     "shell.execute_reply.started": "2025-03-16T11:07:48.695500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='769' max='769' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [769/769 03:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4478414058685303, 'eval_exact_match_non_empty': 50.39843891813396, 'eval_exact_match': 41.542527240201665, 'eval_runtime': 195.3942, 'eval_samples_per_second': 62.939, 'eval_steps_per_second': 3.936, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer_spanbert.evaluate()\n",
    "exact_match_non_empty = results[\"eval_exact_match_non_empty\"]\n",
    "exact_match = results[\"eval_exact_match\"]\n",
    "print(f\"Exact Match for all Examples: {exact_match:.4f}\")\n",
    "print(f\"Exact Match for Non empty answers: {exact_match_non_empty:.4f}\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:13:30.946099Z",
     "iopub.status.busy": "2025-03-16T11:13:30.945823Z",
     "iopub.status.idle": "2025-03-16T11:13:30.952809Z",
     "shell.execute_reply": "2025-03-16T11:13:30.951881Z",
     "shell.execute_reply.started": "2025-03-16T11:13:30.946076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match for all Examples: 41.5425\n",
      "Exact Match for Non empty answers: 50.3984\n"
     ]
    }
   ],
   "source": [
    "exact_match_non_empty = results[\"eval_exact_match_non_empty\"]\n",
    "exact_match = results[\"eval_exact_match\"]\n",
    "\n",
    "print(f\"Exact Match for all Examples: {exact_match:.4f}\")\n",
    "print(f\"Exact Match for Non empty answers: {exact_match_non_empty:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpanBERT-CRF Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:55:59.057372Z",
     "iopub.status.busy": "2025-03-16T06:55:59.057074Z",
     "iopub.status.idle": "2025-03-16T06:55:59.064491Z",
     "shell.execute_reply": "2025-03-16T06:55:59.063789Z",
     "shell.execute_reply.started": "2025-03-16T06:55:59.057349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SpanBERTCRF(torch.nn.Module):\n",
    "    def __init__(self, num_tags):\n",
    "        super(SpanBERTCRF, self).__init__()\n",
    "        self.spanbert = AutoModelForQuestionAnswering.from_pretrained(\"SpanBERT/spanbert-base-cased\")\n",
    "        hidden_size = self.spanbert.config.hidden_size\n",
    "        self.classifier = torch.nn.Linear(hidden_size, num_tags)\n",
    "        self.crf = CRF(num_tags, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, start_positions=None, end_positions=None):\n",
    "        outputs = self.spanbert(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            token_type_ids=token_type_ids,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs.hidden_states[-1]\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        is_training = start_positions is not None and end_positions is not None\n",
    "\n",
    "        if is_training:\n",
    "            crf_tags = torch.zeros(tuple(input_ids.size()), device=input_ids.device)\n",
    "            \n",
    "            for i in range(crf_tags.size()[0]):\n",
    "                crf_tags[i, start_positions[i]:end_positions[i]+1] = 1\n",
    "            \n",
    "            crf_loss = -self.crf(logits, crf_tags, mask=attention_mask.bool(), reduction='mean')\n",
    "            \n",
    "            spanbert_loss = outputs.loss\n",
    "            \n",
    "            total_loss = spanbert_loss + crf_loss\n",
    "            \n",
    "            return {\n",
    "                \"loss\": total_loss,\n",
    "                \"start_logits\": start_logits,\n",
    "                \"end_logits\": end_logits,\n",
    "                \"hidden_states\": outputs.hidden_states\n",
    "            }\n",
    "        else:\n",
    "            crf_tags = self.crf.decode(logits, mask=attention_mask.bool())\n",
    "            \n",
    "            return {\n",
    "                \"start_logits\": start_logits,\n",
    "                \"end_logits\": end_logits, \n",
    "                \"crf_tags\": crf_tags,\n",
    "                \"hidden_states\": outputs.hidden_states\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:55:59.066117Z",
     "iopub.status.busy": "2025-03-16T06:55:59.065797Z",
     "iopub.status.idle": "2025-03-16T06:56:07.015356Z",
     "shell.execute_reply": "2025-03-16T06:56:07.014483Z",
     "shell.execute_reply.started": "2025-03-16T06:55:59.066084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset_crf = train_subset.map(prepare_features, batched=True, remove_columns=train_subset.column_names)\n",
    "val_dataset_crf = val_subset.map(prepare_features, batched=True, remove_columns=val_subset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:07.016569Z",
     "iopub.status.busy": "2025-03-16T06:56:07.016269Z",
     "iopub.status.idle": "2025-03-16T06:56:11.644284Z",
     "shell.execute_reply": "2025-03-16T06:56:11.643309Z",
     "shell.execute_reply.started": "2025-03-16T06:56:07.016537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_spanbert_crf = SpanBERTCRF(num_tags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:11.646589Z",
     "iopub.status.busy": "2025-03-16T06:56:11.646333Z",
     "iopub.status.idle": "2025-03-16T06:56:11.806509Z",
     "shell.execute_reply": "2025-03-16T06:56:11.805778Z",
     "shell.execute_reply.started": "2025-03-16T06:56:11.646566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/SpanBERT-CRF\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"exact_match\",\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:11.807626Z",
     "iopub.status.busy": "2025-03-16T06:56:11.807430Z",
     "iopub.status.idle": "2025-03-16T06:56:11.813540Z",
     "shell.execute_reply": "2025-03-16T06:56:11.812752Z",
     "shell.execute_reply.started": "2025-03-16T06:56:11.807609Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SpanBertCRFTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, num_items_in_batch = None, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        if prediction_loss_only:\n",
    "            return (outputs[\"loss\"].detach() if isinstance(outputs, dict) else outputs[0].detach(), None, None)\n",
    "            \n",
    "        # Extract predictions\n",
    "        start_logits = outputs[\"start_logits\"].detach()\n",
    "        end_logits = outputs[\"end_logits\"].detach()\n",
    "        \n",
    "        # Extract labels\n",
    "        start_positions = inputs[\"start_positions\"]\n",
    "        end_positions = inputs[\"end_positions\"]\n",
    "        \n",
    "        return (\n",
    "            outputs[\"loss\"].detach() if \"loss\" in outputs else None,\n",
    "            (start_logits, end_logits),\n",
    "            (start_positions, end_positions)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:11.814519Z",
     "iopub.status.busy": "2025-03-16T06:56:11.814333Z",
     "iopub.status.idle": "2025-03-16T06:56:11.836717Z",
     "shell.execute_reply": "2025-03-16T06:56:11.836126Z",
     "shell.execute_reply.started": "2025-03-16T06:56:11.814502Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def exact_match_score(predictions, references):\n",
    "    assert len(predictions) == len(references), \"Lists must have the same length\"\n",
    "    matches = sum(p == r for p, r in zip(predictions, references))\n",
    "    return matches / len(references) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:11.837834Z",
     "iopub.status.busy": "2025-03-16T06:56:11.837557Z",
     "iopub.status.idle": "2025-03-16T06:56:11.856030Z",
     "shell.execute_reply": "2025-03-16T06:56:11.855471Z",
     "shell.execute_reply.started": "2025-03-16T06:56:11.837806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    start_predictions, end_predictions = predictions\n",
    "    start_label_ids, end_label_ids = labels\n",
    "    \n",
    "    start_pred = np.argmax(start_predictions, axis=1)\n",
    "    end_pred = np.argmax(end_predictions, axis=1)\n",
    "    \n",
    "    pred_answers = []\n",
    "    ref_answers = []\n",
    "    for i in range(len(start_pred)):\n",
    "        pred_answers.append((start_pred[i], end_pred[i]))\n",
    "        ref_answers.append((start_label_ids[i], end_label_ids[i]))\n",
    "\n",
    "    score_all = exact_match_score(pred_answers, ref_answers)\n",
    "\n",
    "    non_empty_indices = []\n",
    "    for i, (s, e) in enumerate(zip(start_label_ids, end_label_ids)):\n",
    "        if not (s == 0 and e == 0):\n",
    "            non_empty_indices.append(i)\n",
    "\n",
    "    if len(non_empty_indices) == 0:\n",
    "        return {\"exact_match_non_empty\": 0.0, \"exact_match\": score_all}\n",
    "\n",
    "    filtered_start_preds = np.argmax(start_predictions[non_empty_indices], axis=1)\n",
    "    filtered_end_preds = np.argmax(end_predictions[non_empty_indices], axis=1)\n",
    "    filtered_start_labels = start_label_ids[non_empty_indices]\n",
    "    filtered_end_labels = end_label_ids[non_empty_indices]\n",
    "\n",
    "    pred_answers = list(zip(filtered_start_preds, filtered_end_preds))\n",
    "    ref_answers = list(zip(filtered_start_labels, filtered_end_labels))\n",
    "    \n",
    "    score = exact_match_score(pred_answers, ref_answers)\n",
    "    return {\"exact_match_non_empty\": score, \"exact_match\": score_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:56:11.857073Z",
     "iopub.status.busy": "2025-03-16T06:56:11.856826Z",
     "iopub.status.idle": "2025-03-16T06:56:14.741811Z",
     "shell.execute_reply": "2025-03-16T06:56:14.741004Z",
     "shell.execute_reply.started": "2025-03-16T06:56:11.857043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer_spanbert_crf = SpanBertCRFTrainer(\n",
    "    model=model_spanbert_crf,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_crf,\n",
    "    eval_dataset=val_dataset_crf,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T06:57:28.347499Z",
     "iopub.status.busy": "2025-03-16T06:57:28.347185Z",
     "iopub.status.idle": "2025-03-16T08:55:37.120213Z",
     "shell.execute_reply": "2025-03-16T08:55:37.119567Z",
     "shell.execute_reply.started": "2025-03-16T06:57:28.347468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2868' max='2868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2868/2868 1:58:04, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Exact Match Non Empty</th>\n",
       "      <th>Exact Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>14.096000</td>\n",
       "      <td>12.782765</td>\n",
       "      <td>39.234100</td>\n",
       "      <td>19.107985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.247200</td>\n",
       "      <td>10.729434</td>\n",
       "      <td>43.012450</td>\n",
       "      <td>25.613108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.678600</td>\n",
       "      <td>10.372138</td>\n",
       "      <td>46.302832</td>\n",
       "      <td>29.394210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.268700</td>\n",
       "      <td>10.643360</td>\n",
       "      <td>49.545289</td>\n",
       "      <td>30.451293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.117200</td>\n",
       "      <td>11.105186</td>\n",
       "      <td>46.002318</td>\n",
       "      <td>28.841275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.470800</td>\n",
       "      <td>11.901663</td>\n",
       "      <td>47.125600</td>\n",
       "      <td>28.337128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2868, training_loss=8.069557434677911, metrics={'train_runtime': 7088.4083, 'train_samples_per_second': 12.941, 'train_steps_per_second': 0.405, 'total_flos': 0.0, 'train_loss': 8.069557434677911, 'epoch': 6.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_spanbert_crf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T09:09:39.750380Z",
     "iopub.status.busy": "2025-03-16T09:09:39.750053Z",
     "iopub.status.idle": "2025-03-16T09:15:32.492823Z",
     "shell.execute_reply": "2025-03-16T09:15:32.492013Z",
     "shell.execute_reply.started": "2025-03-16T09:09:39.750353Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 10.643360137939453, 'eval_exact_match_non_empty': 49.5452895262298, 'eval_exact_match': 30.45129289315336, 'eval_runtime': 352.7288, 'eval_samples_per_second': 34.865, 'eval_steps_per_second': 2.18, 'epoch': 6.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer_spanbert_crf.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:16:26.281084Z",
     "iopub.status.busy": "2025-03-16T11:16:26.280653Z",
     "iopub.status.idle": "2025-03-16T11:16:26.290749Z",
     "shell.execute_reply": "2025-03-16T11:16:26.289719Z",
     "shell.execute_reply.started": "2025-03-16T11:16:26.281040Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match for all Examples: 30.4513\n",
      "Exact Match for Non empty answers: 49.5453\n"
     ]
    }
   ],
   "source": [
    "exact_match_non_empty = results[\"eval_exact_match_non_empty\"]\n",
    "exact_match = results[\"eval_exact_match\"]\n",
    "\n",
    "print(f\"Exact Match for all Examples: {exact_match:.4f}\")\n",
    "print(f\"Exact Match for Non empty answers: {exact_match_non_empty:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
